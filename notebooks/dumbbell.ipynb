{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tomli\n",
    "import jax\n",
    "import jax.random as jr\n",
    "from jaxlinop import identity\n",
    "from jaxutils import Dataset\n",
    "from geometric_asymptotics.io import load_space\n",
    "from geometric_asymptotics.experiment import generate_kernel_and_training_data, compute_predictions, compute_extrinsic_length_scale, compute_non_asymptotic_expected_error\n",
    "from geometric_asymptotics.plot_mpl import plot_kernel, plot_data, plot_errors\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mesh \n",
    "\n",
    "Assemble adjacency matrix and graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.cwd() / \"..\" / \"config\" / \"dumbbell.toml\", \"rb\") as f:\n",
    "    config = tomli.load(f)\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(graph,coordinates) = load_space(Path.cwd() / \"..\" / config[\"source\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate full training data\n",
    "\n",
    "Generate x-values by sampling random points on the mesh, and y-values by sampling from intrinsic prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(seed)\n",
    "(k1,key) = jr.split(key)\n",
    "(kernels, training_data, test_data) = generate_kernel_and_training_data(graph, coordinates, config, k1)\n",
    "\n",
    "plot_kernel(kernels[0].gram(kernels[2], test_data[0][:config[\"num_plot\"],:]).to_dense())\n",
    "plot_data(training_data[1], training_data[2], lims=(-2,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "For both intrinsic and extrinsic model with a subset of the data points, as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(k2,key) = jr.split(key)\n",
    "(pred_mean, test_pred_mean, test_pred_var, _) = compute_predictions(kernels, training_data, test_data, config, k2)\n",
    "\n",
    "plot_data(*pred_mean, lims=(-2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(*test_pred_mean, lims=(-2,2))\n",
    "plot_data(*test_pred_var, lims=(0,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrinsic length scale\n",
    "\n",
    "Since the extrinsic and intrinsic processes have length scales which are defined only up to some unknown multiplicative constant, we need to find an extrinsic length scale which matches the intrinsic one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(k3,key) = jr.split(key)\n",
    "kappa_extr, posterior_ls, learned_params_ls = compute_extrinsic_length_scale(kernels, training_data, config, k3)\n",
    "print(\"extrinsic optimized length scale:\", kappa_extr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ls_matching = Dataset(X=training_data[1][:config[\"subset_size_int\"],:], y=training_data[2][:config[\"subset_size_int\"],:].reshape(-1,1))\n",
    "plot_kernel(kernels[1].gram(learned_params_ls['kernel'], test_data[1][:config[\"num_plot\"],:]).to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(test_data[1], posterior_ls.predict(learned_params_ls, data_ls_matching)(test_data[1]).mean(), lims=(-2,2))\n",
    "plot_data(test_data[1], posterior_ls.predict(learned_params_ls, data_ls_matching)(test_data[1]).variance(), lims=(0,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-asymptotic expected error\n",
    "\n",
    "Finally, we condition on subsets of data, and compute expected error for the two models considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(k4,key) = jr.split(key)\n",
    "output = compute_non_asymptotic_expected_error(kernels, training_data, test_data, coordinates.shape[0], kappa_extr, config, k4)\n",
    "plot_errors(output[\"expected_error_idxs\"], output[\"expected_errors\"], output[\"expected_errors_extr\"], output[\"expected_errors_approx_intr\"])\n",
    "plot_errors(output[\"expected_error_idxs\"], output[\"expected_errors_std\"], output[\"expected_errors_extr_std\"], output[\"expected_errors_approx_intr_std\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting output\n",
    "\n",
    "This code produces output for the plotting figures in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(k5,k6,key) = jr.split(key,3)\n",
    "y_sample = (kernels[0].gram(kernels[2], test_data[0]) + identity(coordinates.shape[0]) * config[\"noise_variance\"]).to_root() @ jr.normal(k5, (coordinates.shape[0], 1))\n",
    "y_sample_extr = (kernels[1].gram(learned_params_ls['kernel'], test_data[1]) + identity(coordinates.shape[0]) * config[\"noise_variance\"]).to_root() @ jr.normal(k6, (coordinates.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(test_data[1], y_sample, lims=(-2,2), colorbar=False, file_name=Path.cwd() / \"..\" / \"plot\" / \"db_sample_intr.png\")\n",
    "plot_data(test_data[1], y_sample_extr, lims=(-2,2), colorbar=False, file_name=Path.cwd() / \"..\" / \"plot\" / \"db_sample_extr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_point_idx = 864\n",
    "kernel_values = kernels[0].cross_covariance(kernels[2], test_data[0], test_data[0][None,kernel_point_idx,:])\n",
    "kernel_values_extr = kernels[1].cross_covariance(learned_params_ls['kernel'], test_data[1], test_data[1][None,kernel_point_idx,:])\n",
    "plot_data(test_data[1], kernel_values, lims=(0,1), colorbar=False, highlight = test_data[1][kernel_point_idx,:], file_name=Path.cwd() / \"..\" / \"plot\" / \"db_kernel_intr.png\")\n",
    "plot_data(test_data[1], kernel_values_extr, lims=(0,1), colorbar=False, highlight = test_data[1][kernel_point_idx,:], file_name=Path.cwd() / \"..\" / \"plot\" / \"db_kernel_extr.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
